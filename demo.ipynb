{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get speaker recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\__repos\\wut_easar\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from Utils.config import (\n",
    "    TEST_DATA_DIR, \n",
    "    SPEAKERS,\n",
    "    DATA_DIR,\n",
    "    UBU_DATA_DIR, \n",
    "    SELECTED_KEYWORD, \n",
    "    SELECTED_SPEAKER, \n",
    "    ALTERNATIVE_KEYWORD_1, \n",
    "    ALTERNATIVE_SPEAKER_1,\n",
    "    ALTERNATIVE_KEYWORD_2,\n",
    "    ALTERNATIVE_SPEAKER_2\n",
    ")\n",
    "from Utils.create_model import create_model\n",
    "from Utils.load_test_wav import load_test_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\__repos\\wut_easar\\venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\__repos\\wut_easar\\venv\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " static_stft (Spectrogram)   (None, 257, 63, 1)        263168    \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 62, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 85, 20, 16)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 27200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 244809    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508057 (1.94 MB)\n",
      "Trainable params: 508057 (1.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model('spectrogram')\n",
    "model.load_weights('Models/70_epochs_spectrogram.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.05557251 -0.05883789 -0.0513916  ...  0.03161621  0.02597046\n",
      "   0.03268433]], shape=(1, 12960), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "signal = load_test_wav(f'{TEST_DATA_DIR}/Hillary_Clinton/dignity.wav')\n",
    "print(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12960)\n",
      "padded\n",
      "(1, 16000)\n",
      "dim extended\n",
      "(1, 1, 16000)\n"
     ]
    }
   ],
   "source": [
    "print(signal.shape)\n",
    "signal = tf.pad(signal, [[0, 0], [0, 16000 - 12960]])\n",
    "print(\"padded\")\n",
    "print(signal.shape)\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "print('dim extended')\n",
    "print(signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.6041788e-16, 2.3670447e-20, 1.0000000e+00, 2.9069542e-12,\n",
       "        6.9307100e-16, 6.9170922e-13, 1.2936300e-26, 6.0045793e-15,\n",
       "        4.6369544e-15]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = SPEAKERS[y_pred_classes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary_Clinton\n"
     ]
    }
   ],
   "source": [
    "print(speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get keyword spotting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "from Utils.config import (\n",
    "    UBU_DATA_DIR, \n",
    "    SELECTED_KEYWORD, \n",
    "    SELECTED_SPEAKER, \n",
    "    ALTERNATIVE_KEYWORD_1, \n",
    "    ALTERNATIVE_SPEAKER_1,\n",
    "    ALTERNATIVE_KEYWORD_2,\n",
    "    ALTERNATIVE_SPEAKER_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-01-21 16:21:06 cloud:58] Found existing object /home/lorca/.cache/torch/NeMo/NeMo_1.22.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2024-01-21 16:21:06 cloud:64] Re-using file from: /home/lorca/.cache/torch/NeMo/NeMo_1.22.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2024-01-21 16:21:06 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-01-21 16:21:07 features:289] PADDING: 16\n",
      "[NeMo I 2024-01-21 16:21:07 save_restore_connector:249] Model EncDecCTCModel was successfully restored from /home/lorca/.cache/torch/NeMo/NeMo_1.22.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "asr_model = nemo_asr.models.EncDecCTCModel.from_pretrained(\n",
    "    model_name=\"QuartzNet15x5Base-En\", strict=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiences\n",
      "Hillary_Clinton\n",
      "\n",
      "challenges\n",
      "Yamini_Ravindran\n",
      "\n",
      "forces\n",
      "Ronald_Reagan\n"
     ]
    }
   ],
   "source": [
    "print(SELECTED_KEYWORD)\n",
    "print(SELECTED_SPEAKER)\n",
    "print()\n",
    "print(ALTERNATIVE_KEYWORD_1)\n",
    "print(ALTERNATIVE_SPEAKER_1)\n",
    "print()\n",
    "print(ALTERNATIVE_KEYWORD_2)\n",
    "print(ALTERNATIVE_SPEAKER_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker and keyword match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/keywords//Hillary_Clinton/experiences.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{TEST_DATA_DIR}/{SELECTED_SPEAKER}/{SELECTED_KEYWORD}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = load_test_wav(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 81ms/step\n"
     ]
    }
   ],
   "source": [
    "# pre-process the signal\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "\n",
    "# post-process the logits\n",
    "y_pred = model.predict(signal)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: \"Hillary_Clinton\"\n"
     ]
    }
   ],
   "source": [
    "speaker = SPEAKERS[y_pred_classes[0]]\n",
    "print(f'Speaker: \"{speaker}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/__repos/wut_easar/project/Data/keywords/Hillary_Clinton/experiences.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{UBU_DATA_DIR}/keywords/{SELECTED_SPEAKER}/{SELECTED_KEYWORD}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febd222e52c84803af09623ea22fbf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"experiences\"\n"
     ]
    }
   ],
   "source": [
    "files = [audio_filename]\n",
    "transcript = asr_model.transcribe(paths2audio_files=files)[0]\n",
    "print(f'Transcript: \"{transcript}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword ID: Success!\n"
     ]
    }
   ],
   "source": [
    "if transcript == f'{SELECTED_KEYWORD}':\n",
    "    print('Keyword ID: Success!')\n",
    "else :\n",
    "    print('Keyword ID: Failure!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: Success!\n"
     ]
    }
   ],
   "source": [
    "if speaker == f'{SELECTED_SPEAKER}':\n",
    "    print('Speaker ID: Success!')\n",
    "else:\n",
    "    print('Speaker ID: Failure!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker match but keyword mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/keywords//Hillary_Clinton/challenges.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{TEST_DATA_DIR}/{SELECTED_SPEAKER}/{ALTERNATIVE_KEYWORD_1}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = load_test_wav(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# pre-process the signal\n",
    "signal = tf.pad(signal, [[0, 0], [0, 16000 - 9760]])\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "\n",
    "# post-process the logits\n",
    "y_pred = model.predict(signal)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: \"Hillary_Clinton\"\n"
     ]
    }
   ],
   "source": [
    "speaker = SPEAKERS[y_pred_classes[0]]\n",
    "print(f'Speaker: \"{speaker}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/__repos/wut_easar/project/Data/keywords/Hillary_Clinton/challenges.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{UBU_DATA_DIR}/keywords/{SELECTED_SPEAKER}/{ALTERNATIVE_KEYWORD_1}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3165bee96d19475e8121c0b7361e65e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"challenges\"\n"
     ]
    }
   ],
   "source": [
    "files = [audio_filename]\n",
    "transcript = asr_model.transcribe(paths2audio_files=files)[0]\n",
    "print(f'Transcript: \"{transcript}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword ID: Failure!\n"
     ]
    }
   ],
   "source": [
    "if transcript == f'{SELECTED_KEYWORD}':\n",
    "    print('Keyword ID: Success!')\n",
    "else :\n",
    "    print('Keyword ID: Failure!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: Success!\n"
     ]
    }
   ],
   "source": [
    "if speaker == f'{SELECTED_SPEAKER}':\n",
    "    print('Speaker ID: Success!')\n",
    "else:\n",
    "    print('Speaker ID: Failure!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker mismatch but keyword match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/keywords//Yamini_Ravindran/experiences.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{TEST_DATA_DIR}/{ALTERNATIVE_SPEAKER_1}/{SELECTED_KEYWORD}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = load_test_wav(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "# pre-process the signal\n",
    "signal = signal[:, :16000]\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "\n",
    "# post-process the logits\n",
    "y_pred = model.predict(signal)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: \"Nelson_Mandela\"\n"
     ]
    }
   ],
   "source": [
    "speaker = SPEAKERS[y_pred_classes[0]]\n",
    "print(f'Speaker: \"{speaker}\"')\n",
    "# note that out-of-distibution speaker is not recognized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/__repos/wut_easar/project/Data/keywords/Yamini_Ravindran/experiences.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{UBU_DATA_DIR}/keywords/{ALTERNATIVE_SPEAKER_1}/{SELECTED_KEYWORD}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ec5aaa3e04b958d0c831cf6c005e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"experiences\"\n"
     ]
    }
   ],
   "source": [
    "files = [audio_filename]\n",
    "transcript = asr_model.transcribe(paths2audio_files=files)[0]\n",
    "print(f'Transcript: \"{transcript}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword ID: Success!\n"
     ]
    }
   ],
   "source": [
    "if transcript == f'{SELECTED_KEYWORD}':\n",
    "    print('Keyword ID: Success!')\n",
    "else :\n",
    "    print('Keyword ID: Failure!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: Failure!\n"
     ]
    }
   ],
   "source": [
    "if speaker == f'{SELECTED_SPEAKER}':\n",
    "    print('Speaker ID: Success!')\n",
    "else:\n",
    "    print('Speaker ID: Failure!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker mismatch and keyword mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/keywords//Ronald_Reagan/forces.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{TEST_DATA_DIR}/{ALTERNATIVE_SPEAKER_2}/{ALTERNATIVE_KEYWORD_2}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = load_test_wav(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "# pre-process the signal\n",
    "signal = tf.pad(signal, [[0, 0], [0, 16000 - 10880]])\n",
    "signal = tf.expand_dims(signal, 0)\n",
    "\n",
    "# post-process the logits\n",
    "y_pred = model.predict(signal)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker: \"Ronald_Reagan\"\n"
     ]
    }
   ],
   "source": [
    "speaker = SPEAKERS[y_pred_classes[0]]\n",
    "print(f'Speaker: \"{speaker}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/__repos/wut_easar/project/Data/keywords/Ronald_Reagan/forces.wav\n"
     ]
    }
   ],
   "source": [
    "audio_filename = f\"{UBU_DATA_DIR}/keywords/{ALTERNATIVE_SPEAKER_2}/{ALTERNATIVE_KEYWORD_2}.wav\"\n",
    "print(audio_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566b55467796491487cd1a7853b73dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: \"forces\"\n"
     ]
    }
   ],
   "source": [
    "files = [audio_filename]\n",
    "transcript = asr_model.transcribe(paths2audio_files=files)[0]\n",
    "print(f'Transcript: \"{transcript}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword ID: Failure!\n"
     ]
    }
   ],
   "source": [
    "if transcript == f'{SELECTED_KEYWORD}':\n",
    "    print('Keyword ID: Success!')\n",
    "else :\n",
    "    print('Keyword ID: Failure!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker ID: Failure!\n"
     ]
    }
   ],
   "source": [
    "if speaker == f'{SELECTED_SPEAKER}':\n",
    "    print('Speaker ID: Success!')\n",
    "else:\n",
    "    print('Speaker ID: Failure!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
